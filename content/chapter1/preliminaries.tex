\section{Preliminary Setup}\label{sec:preliminary-setup}

\subsection{The Model}\label{subsec:the-model}
An important part of any study is the model it uses to represent the system being
studied.
We employ a model described by \etal{Cohensius} in their 2017
article~\cite{Cohensius2017}.
This model places voters' preferences in a single-dimension continuous
metric~space~\systemspace, such as in~\autoref{fig:system-metric-space}.
In this model, two points that are close together in the metric space represent
similar preferences, while two points that are far apart represent very different
preferences.
As a point moves further away from the agent's preference, the agent likes it less.
This model works best when an upper and lower bound is provided, such as only
allowing agents to vote in the interval $[-1, 1]$, to prevent agents from voting
extremely far in either direction and so potentially biasing the vote.
Not all methods of voting are susceptible to such attacks, but it must be a
consideration for those that are.

The difference between multiple equidistant points in the model may not be equivalent
to the agents.
For example, an agent who must spend \$30 may prefer spending more money rather than
less.
As such, even though \$29 and \$31 are equidistant to \$30, an agent may vastly
prefer \$31 over \$29.
However, for our model, we will assume agents only care about the distance from their
preference, rather than if it is greater or less than some amount.

\begin{figure}[htbp]
    \centering
    \input{common/figures/system-metric-space.tikz}
    \caption{
        Example of a 1D continuous preference metric space, where \truthof{x} represents
        the preference of agent $x$.
        The x-axis represents some preference space.
        An agent can have a preference anywhere within this space.
        One way to interpret the model is to have the leftmost point be the most
        against some idea and the rightmost point is the most in favor of the same idea.
        Importantly, points towards the center of the space are the most ambivalent,
        neutral, or central on the idea.
        Alternatively, points towards the center may also prefer some type of
        compromise or alternative solution instead.
    }
    \label{fig:system-metric-space}
\end{figure}

Such a model is extremely flexible and can be interpreted in different ways.
When applied to binary for-or-against voting problems, options can be placed at either
extreme of the interval.
As an example, shareholders at some company are voting on new data collection policies.
Using the interval $[-1, 1]$, we can place `no collection at all' at -1, and `heavy
collection' at 1.
Agents vote according to their preference: -1 for no collection, 1 for heavy collection.
So far, everything works the same as a normal vote.
However, due to the continuous nature of the voting space, the agents can vote
anywhere in the given interval.
Therefore, agents who do not care one way or the other can vote at 0 instead of being
forced to choose an option.
Additionally, those that are only slightly in favor (meaning they would prefer
collection but do not really care that much) can choose some value between 0 and 1.
Once the votes are aggregated, the result can be rounded to whichever option is
closest.
The continuous space allows agents to better express themselves according to what
their actual preference is, instead of being forcibly binned into one value or the
other.

Alternatively, if the majority of the votes are about the center, it may be a sign
neither option is satisfactory.
Using the data collection example, we can reinterpret 0 to mean the agents do not
mind collecting users' data, but also do not personally care either way.
These agents would vote around 0 to avoid imposing.
By making the agents aware of how 0 will be interpreted, they can express their
dissatisfaction by voting at or around 0.
Normally, voting goes through a bargaining and an enforcement
phase~\cite{Fearon1998}, but if a sufficient number of agents vote close to 0, the
group can reopen discussion about the topic and re-bargain before conducting a new vote.
This enhances the cooperation aspect of voting, and creates a fundamental change:
voting is no longer the end of the negotiation, but rather part of it.

Finally, the continuous space model allows for another, very powerful interpretation:
interpreting the votes and result as continuous values.
For example, imagine Congress is voting on how much to allocate to the defense budget.
In this scenario, Congress can decide to allocate anywhere between \$0 and \$1,000.\footnote{
    Naturally, these values are not realistic and are meant to be representative.
}
A voter can place their vote anywhere between those values, and the result of the
vote can be how much Congress allocates.
Say there are three voters, each with their own preferences, and all voters are
active (no voter delegates their vote).
Agent $a$ prefers \$750, $b$ prefers \$600, and $c$ prefers \$250.
One way we could aggregate these preferences is by finding their mean.
By averaging these preferences, the system would output
$\frac{\$(750 + 600 + 250)}{3 \text{ voters}} = \frac{\$1600}{3 \text{ voters}} =
\$533.33$,
which would be the amount allocated to the defense budget.
Being able to vote on continuous problems and yield a continuous output, as well as
working with binary issues, makes the model extremely flexible and allows it to
tackle any number of problems.

We are also able to easily calculate error using a continuous space.
The error can simply be the distance from the result of the system when all agents
are active, and the result under proxy voting.

The flexibility of the continuous model in both the discrete and continuous realms, its
ability to use different voting rules, easy interpretability, and easy error
calculation are the reasons it is employed in this study.
We will focus primarily on the continuous instead of the discrete output of the
model, since observing the continuous output allows for more granularity in the
differences between proxy and non-proxy voting, as well as in the differences between
voting rules.

\subsection{Voting Mechanisms}\label{subsec:voting-mechanisms}
This study also makes use of \textit{voting mechanisms} or \textit{voting rules},
which are functions that map a set of preferences in~\systemspace\ to an outcome that
also exists in~\systemspace.
For these, we take inspiration from \etal{Bulteau}'s~\cite{Bulteau2021} work in
aggregating one-dimensional single-winner elections by using their $L_p$ aggregation
methods, as well as mixing in plurality.
$L_p$ aggregation methods work by minimizing the sum of distances to the power of $p$
($d^{\,p}$, where $d$ is a distance) between a possible solution and the voters'
preferences.
Naturally, since~\cite{Bulteau2021} did not use weighted proxies, these methods need
to be adjusted to allow for weight.
Below, \agentweight\ represents the weight of an agent \agent, and \systemproxies\ is
the set of active voters ordered by preference.
Additionally, \agenttruth\ is the preference of an agent, and \system\ is the set of
all agents.
With these notations, the mechanisms we use are
\begin{enumerate}
    \item {
        \textit{Median ($L_1$)}, defined as
        $\input{common/figures/equations/weighted-median}$.
         % 05/13/2023: \vicki{
         %  In your original definition, you need to control j (starting at 1) so we know it is a subscript in Sp.
% This notation doesn't say what you want.  Nothing says that j begins at 1 in Sp.
%
% Better as:
% let i = min i such that (sum(j=1,i) w(Spj) >w(S)/2)
% md(Sp) = T(ai)
%
%
%          }
        % This definition is saying the median is the preference of the first agent
        % whose additional weight makes the sum of weights more than half the total
        % weight of the system.
        %
        % `j` refers to `agent j,` as in the agent from the set of proxies that is
        % not agent i. I could start at agent 1 and sum the weights to agent i.
        % Instead I said we sum the other agents (agent j) from the set of proxies
        % up to but not including agent i (which is why it goes to agent (i - 1)).
        %
        % I deliberately add agent i outside the sum to make it extremely apparent
        % their weight is the weight that achieves the median.
        Essentially, the median is the active agent whose additional weight makes the
        sum of weights become equal to or greater than half the total weight of the
        system.
        The sum will occur in the same order as the ordering of voters in
        \systemproxies.
        There is an edge case where the sum of weight perfectly reaches half the
        total weight.
        When this occurs, the preference that reaches half is called the lower
        weighted median, and the preference that starts from half is called the higher
        weighted median.
        In this case both the lower and higher weighted medians,
        % 05/05/2023: \vicki{Awkward, lower weighted median isn't really a thing.}
        % I'm not sure what else to call it. A quick internet search indicates these
        % are known terms for the lower and higher bounds of a weighted median.
        % I've added a sentence clarifying what these terms mean.
        as well as any value in between, can claim to be the median.
        This is similar to when there are an even number of preferences in a normal
        median.
        In this case, we take the average between the preference of the agent with
        the highest preference in the lower median half and the agent with the lowest
        preference in the higher half of the weighted median.
    }
    \item {
        \textit{Mean ($L_2$)}, defined as
        $\input{common/figures/equations/weighted-mean}$.
         % \vicki{
         %  I'm confused.  Even if Sp is only the active agents, isn't the weight of Sp the same as the weight of S?
         %   If so, why use S at all in this equation?
         % }
        % S and Sp are different, S being the set of all agents and Sp being the set
        % of active agents.
        % I realized I forgot to define S, so I've added that above.
        %
        % I feel it's important to make this distinction because we want to divide by
        % the weight of all agents, not just the weight of the active agents.
        This is a typical weighted average.
    }
    \item {
        \textit{Mid-range ($L_\infty$)}, defined as
        $\input{common/figures/equations/weighted-midrange}$, where $n$ is the number
        of proxies
        This equation essentially means the preference of the active agent with the
        lowest preference plus the preference of the active agent with the
        highest preference, divided by two.
        %
        % 05/13/2023 \vicki{Since Sp is ordered, don't you just want T(Sp1) and T(Spn)?
        % You say SP is the ordered set of active voters.  You need to say it is ordered by preference (not weight).
        % I wonder if  you just need better notation.  Instead of Sp, call it W (for weighted proxies, ordered by preference) and then elements can be w1, w2, ... wn
        % }
        % I'll change Sp to W, but w is already used to mean the weight function.
    }
\end{enumerate}
In addition to applying these voting mechanisms on the set of active agents, we
% 05/05/2023: \vicki{Not sure what is meant by additionally.  Were you meaning that the
% voting mechanism was used for some other reason?}
% Yes, the mechanisms as described above are applied to the weighted set of active
% voters. Here I'm explaining  my baseline, those being using these mechanisms on all
% voter, active and inactive, as well as applying them to only the active voters
% without weights. I've rephrased things to try to make it more apparent.
apply these mechanisms to active voters without weights (to simulate if proxy voting was
not allowed) and all voters, both active and inactive, (to simulate the best case
where all agents vote).
These additional calculations serve as baselines to determine how well proxy voting
works in these scenarios.

\subsection{Coordination Mechanisms}
\label{subsec:coordination-mechanisms}
There are also several ways an individual proxy can agree to cast its vote on behalf
of its constituents.
Each has different advantages and disadvantages for the proxy, its constituents, and
the system as a whole.
We will examine five different `coordination' mechanisms that `groups' (meaning a
proxy and its constituents) can use:
% 05/05/2023: \vicki{
%   Consider removing the "no preference change" to the first four, including
%   preference change for the last four.
%   The reader isn't ready for the preference change idea, as it hasn't been introduced,
%   so it is just confusing.
% }
\begin{enumerate}
    \item {
        \textit{Expert}.
        The group applies its total weight to the proxy's preference.
    }
    % \item {
    %     \textit{Active Only}.  \vicki{The previous sentence indicates these govern how groups coordinate.  This doesn't really meet that criteria.
 % The name also seems odd. }
 %        Only active agents vote with no additional weight.
 %    }
    % This is a baseline which I discussed previously, so I've removed it
    \item {
        \textit{Cooperative Mean}.
        The group allocates its weight to the mean of the proxy's and its
        constituents' preferences.
    }
    \item {
        \textit{Cooperative Median}.
        The group allocates its weight to the median of the proxy's and its
        constituents' preferences.
    }
    % \item {
    %     \textit{Preference change - Expert}.
    %     The group applies its total weight to the proxy's preference but allows the proxy to change its vote.
    %     This is useful for cases when a proxy is deemed by its constituents as an
    %     `expert', as discussed by James Miller~\cite{Miller1969}.
    %     However, active agents' preferences have changed as they have participated in
    %     deliberation and discussion with the other active voters.
    % }
    % \item {
    %     \textit{Preference change - Expert with Consequences}.
    %     The proxy is an expert and the group allocates its weight to the proxy's
    %     preference, but active agents', including the proxy's, preferences have changed.
    %     However, due to this change the proxy is only allowed vote for itself,
    %     meaning it can only use its own weight.
    %     This causes its constituents to be unrepresented.
    %     This represents situations where a proxy is considered an expert, but the
    %     constituents impose a condition that the proxy can only represent them if
    %     they vote a certain way.
    %
    %     Note this is analogous to when agents change their preference and only active
    %     agents are allowed to vote.
    %     % 05/05/2023: \vicki{Not if the proxy doesn't change their vote.  I think you
    %     % have to handle this case because otherwise, it makes no sense to have a new name.
    %     % }
    %     % Naturally this doesn't apply to when agents change their vote. That's why I
    %     % specify they've changed their preference. Nevertheless, I've extracted
    %     % these and explain the coordination mechanisms are also applied to when the
    %     % agents change their votes.
    %
    % }
    % \item {
    %     \textit{Preference change - Cooperative Mean}.
    %     The group allocates its weight to the mean of the proxy's and its
    %     constituents' preferences.
    %     However, active agents' preference has changed as it has participated in
    %     deliberation and discussion with the other active voters.
    %
    % }
    % \item {
    %     \textit{Preference change - Cooperative Median}.
    %     The group allocates its weight to the median of the proxy's and its
    %     constituents' preferences.
    %     However, active agents' preferences have changed due to deliberation.
    % }
\end{enumerate}
These mechanisms are used in an attempt to simulate real-world consequences of proxy
voting, as well as identify potential techniques to deter or mitigate a proxy's
ability to swing the system by aggregating a large amount of weight and abusing it.

These mechanisms will additionally be applied after active agents change their
preferences in order to determine how well they represent the agents after
deliberation has occurred.
